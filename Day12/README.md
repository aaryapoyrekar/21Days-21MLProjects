# ğŸ–¼ï¸ Image Super-Resolution using U-Net (32Ã—32 â†’ 128Ã—128)

## ğŸ“Œ Project Overview
This project implements an **image super-resolution system** using a **U-Net architecture**.  
The goal is to reconstruct a **high-resolution image (128Ã—128)** from a **low-resolution input (32Ã—32)**.

Super-resolution is a fundamental problem in computer vision, widely used in:
- Image enhancement
- Medical imaging
- Surveillance
- Photography and media restoration

---

## ğŸ¯ Objective
- Input: **32 Ã— 32 RGB image**
- Output: **128 Ã— 128 RGB image**
- Learn a mapping that restores spatial details lost during downsampling

---

## ğŸ§  Why U-Net?
U-Net is well-suited for image-to-image tasks because:
- The **encoder** captures global context
- The **decoder** reconstructs spatial details
- **Skip connections** preserve fine-grained information

This makes U-Net effective for super-resolution problems.

---

## ğŸ—‚ï¸ Dataset
- **CelebA Dataset**
- Images are:
  - Resized to **128Ã—128** as ground truth
  - Downscaled to **32Ã—32** as model input
- Pixel values normalized to `[0, 1]`

---

## ğŸ—ï¸ Model Architecture
- Encoderâ€“decoder U-Net
- Convolutional layers with Batch Normalization and ReLU
- MaxPooling for downsampling
- Transposed Convolutions for upsampling
- Extra upsampling layers to reach **128Ã—128 resolution**
- Final `1Ã—1` convolution to generate RGB output

---

## âš™ï¸ Training Configuration
- **Loss Function:** Mean Absolute Error (MAE)
- **Optimizer:** Adam
- **Batch Size:** 32
- **Training Strategy:** Generator-based training
- **Framework:** TensorFlow / Keras

---

## ğŸ“Š Results
- MAE loss decreases across epochs, indicating learning
- Visual inspection shows progressive improvement in image clarity
- Early predictions are blurry (expected) and improve with training

---

## ğŸ“ˆ Sample Outputs
Each epoch compares:
1. Original Image
2. Ground Truth (128Ã—128)
3. Low-Resolution Input (32Ã—32 â†’ upscaled)
4. Model Prediction

This provides clear qualitative feedback on training progress.

---

## ğŸš€ How to Run
1. Load the CelebA dataset
2. Run cells sequentially:
   - Imports
   - Model definition
   - Data generator
   - Training
   - Visualization
3. Train the model and observe sample outputs

---

## ğŸ”® Future Improvements
- Use perceptual or SSIM loss
- Add adversarial training (SRGAN)
- Increase dataset diversity
- Train for more epochs
- Experiment with deeper architectures

---

## âœ… Conclusion
This project demonstrates that **U-Net can effectively perform image super-resolution**, converting low-resolution **32Ã—32 images into high-resolution 128Ã—128 outputs**.  
The results validate the power of encoder-decoder architectures for pixel-level reconstruction tasks.

---

## ğŸ‘¨â€ğŸ’» Author
**Aarya Poyrekar**  
Day 12 â€“ 21 Days, 21 ML Projects
